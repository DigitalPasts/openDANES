[
  

  
    {} ,

  

  

  
    {} ,

  

  

  
    {} ,

  

  

  

    
    

    {
      "title"    : "Preprocessing Ancient Texts - Challenges and Comparisons of Python and R Resources",
      "authors" : "chatGPT",
      "tags"     : "python, R, pre-processing",
      "doi"       : "10.5281/zenodo.6411251",
      "submit-date" : "2023-04-07",
      "publish-date" : "2023-04-07",
      "peer-review-date" : "2023-04-07",
      "update-date" : "",
      "url"      : "/openDANES/pages/paper1.html",
      "type"     : "white-paper",
      "summary"     : "This is an example paper created by chatGPT.",
      "content"     : "chatGPT                                                                                                      1                                                                                                                                                               1 openAI                      Submitted on: April 07, 2023      Published on: April 07, 2023              Peer reviewed: April 07, 2023                                  Reviewed by:         chatGPT                                                                                            doi                                                    Summary: This is an example paper created by chatGPT.                                      #python                  #R                  #pre-processing                        About this paperAll the text contained in this paper, except for this section, was created by chatGPT. It was generated by the following prompt:  We are developing a website called openDANES, a platform for tutorials and white papers about using computational methodologies for ancient Near Eastern studies.  Can you write an example white paper that will include all possible markdown syntax? (different heading types, tip prompts, images, etc.). This will be used as a template example.  The example white paper should be about current challenges in preprocessing ancient texts using available online resources, particularly comparing current resources in python versus current resources in R.  As this is a demo, please include jokes to make it funny and entertaining!Then, for the peer-review process, a new conversation with chatGPT was started where the following prompt was given:  I need you to perform an academic peer review for a white paper submitted to openDANES, a platform for tutorials and white papers about using computational methodologies for ancient Near Eastern studies.  Please critically answer the following questions:      should the paper be published in openDANES?    are there any corrections you would suggest to the text, which would make it clearer or strengthen the points the author is making? Please write them out.    are the jokes funny enough? If not, can you improve them?  Then the original version of this paper was copy-pasted.ChatGPT provided the following answers:  Overall, the paper is well-written, informative, and engaging. It addresses an important and timely topic, and provides a useful comparison of Python and R resources for preprocessing ancient texts. Below are my answers to the three questions posed:  (1) Yes, the paper should be published in openDANES. It meets the platform’s criteria of providing tutorials and white papers about using computational methodologies for ancient Near Eastern studies.  (2) There are no major corrections that I would suggest. However, I have a few minor suggestions that may strengthen the points the author is making:      The introduction could benefit from a more specific statement of the problem or research question that the paper addresses.    In the Python section, the author mentions sentiment analysis and questions its usefulness for ancient texts. It may be helpful to provide an example or explanation of why this is the case.    In the R section, the author could expand on the benefits of the tidytext and quanteda packages. What specific features or functionalities do these packages offer?    (3) The jokes are light-hearted and add to the overall tone of the paper. I don’t think they detract from the content, and therefore don’t need to be improved.  Overall, the paper is a valuable contribution to the field of ancient Near Eastern studies and computational methodologies.Then, we asked chatGPT to rewrite the paper with the suggested corrections. The text below is the result of that peer-review.The text has not been adapted whatsoever by a human. This is purely meant as an example of how a formatted paper looks like.Preprocessing Ancient Texts: Challenges and Comparisons of Python and R ResourcesIntroductionAs the field of ancient Near Eastern studies becomes increasingly reliant on computational methodologies, scholars are faced with the challenge of preprocessing ancient texts using available online resources. In this white paper, we will explore the current challenges of preprocessing ancient texts and compare the available resources in Python and R. Specifically, we aim to answer the question: which language is better for preprocessing ancient texts - Python or R?The Challenge of Preprocessing Ancient TextsPreprocessing ancient texts presents a unique set of challenges that are not encountered when working with modern texts. For one thing, ancient texts often come in a variety of languages, many of which are no longer spoken. Additionally, ancient texts may be damaged or incomplete, making them difficult to read or understand. And let’s not forget the challenge of deciphering ancient scripts!But fear not, intrepid scholars! With the help of computational methodologies, we can overcome these challenges and gain new insights into the ancient world.Python Resources for Preprocessing Ancient TextsPython has a wealth of resources available for preprocessing ancient texts, including the Natural Language Toolkit (NLTK) and the TextBlob library. These tools can be used to tokenize text and perform part-of-speech tagging. However, while Python also has the capability to perform sentiment analysis, it is unlikely to be useful for ancient texts since we have no way of knowing how the authors were feeling.Of course, as with any programming language, there are some quirks to be aware of. As the saying goes, “Python is the second-best language for everything.” But don’t let that discourage you - with a little perseverance, you can accomplish great things in Python.R Resources for Preprocessing Ancient TextsR is another popular language for preprocessing ancient texts, with resources like the tidytext package and the quanteda package. These tools can be used to perform a variety of text analysis tasks, such as word frequency analysis and topic modeling.The tidytext package offers functionality for performing sentiment analysis specifically for texts in English, which may be useful for some ancient texts written in English. The quanteda package provides a variety of text processing and analysis functionalities, including tokenization, part-of-speech tagging, and keyword extraction. It also offers support for many different languages and scripts.However, R has its own quirks and challenges. As one wise person once said, “R is like a drug. Once you start using it, you can’t stop.” So be careful when delving into the world of R - you may find yourself unable to escape!Comparing Python and R ResourcesAs we have seen, both Python and R offer valuable resources for preprocessing ancient texts. Which language is better for this task ultimately depends on your specific needs and preferences. Python may be more intuitive for those who are new to programming, while R may be better suited for those who are already familiar with statistics and data analysis.ConclusionIn conclusion, preprocessing ancient texts presents a unique set of challenges, but with the help of computational methodologies, we can overcome these challenges and gain new insights into the ancient world. Python and R both have their own strengths and quirks, so the best choice depends on your specific needs and preferences.And remember, when in doubt, just keep laughing - because as the great scholar Confucius once said, “Everything has beauty, but not everyone sees it.”"
    } ,

  

  

  

    
    

    {
      "title"    : "Challenges in OCR for Cuneiform Texts",
      "authors" : "Shai Gordin, Avital Romach",
      "tags"     : "cuneiform, OCR",
      "doi"       : "10.5281/zenodo.6411251",
      "submit-date" : "2023-04-16",
      "publish-date" : "2023-04-16",
      "peer-review-date" : "2023-04-16",
      "update-date" : "",
      "url"      : "/openDANES/pages/paper2.html",
      "type"     : "white-paper",
      "summary"     : "An overview of the current challenges in cuneiform OCR",
      "content"     : "Shai Gordin                                                                                                      1                                                                                                                                                                                   2                                                                                                                                                                                                                                                                     ,             Avital Romach                                                                                                                                                                                                                                                      2                                                                                                                       3                                                                                                                                                                                             1 Ariel University                      2 Digital Pasts Lab                      3 Yale University                      Submitted on: April 16, 2023      Published on: April 16, 2023              Peer reviewed: April 16, 2023                                  Reviewed by:         chatGPT                                                                                            doi                                                    Summary: An overview of the current challenges in cuneiform OCR                                      #cuneiform                  #OCR                        Optical Character Recognition (OCR) has made significant progress in recent years, but it still faces significant challenges when it comes to cuneiform texts. Cuneiform was the first system of writing developed by humans, used by ancient civilizations in Mesopotamia, and is a complex script with over 1,000 characters. In this paper, we will discuss the challenges of OCR for cuneiform texts, as well as some potential solutions.Character RecognitionCuneiform characters are typically composed of wedge-shaped marks impressed into clay tablets. OCR software faces difficulties in recognizing these characters due to the complexity of the shapes, which can have many variations. Additionally, the script has no clear distinction between upper and lowercase letters, making it difficult for OCR software to differentiate between them. The lack of standardization in character shape and size also poses a significant challenge for OCR.Contextual AnalysisCuneiform texts often contain ligatures, where two or more characters are merged into a single glyph. This merging can create ambiguity in the interpretation of individual characters, which can lead to errors in OCR. Contextual analysis is essential for resolving these ambiguities, but it can be challenging to implement in OCR software.Training DataOCR software relies heavily on training data to recognize characters accurately. However, obtaining a large dataset of cuneiform characters for training can be difficult due to the scarcity of cuneiform texts. Additionally, the variation in character shapes and sizes makes it challenging to create a comprehensive training set.SolutionsSeveral potential solutions have been proposed to address these challenges in OCR for cuneiform texts. One solution is to create specialized OCR software specifically for cuneiform texts, which can incorporate contextual analysis and machine learning algorithms trained on a small dataset of cuneiform characters. Another solution is to develop software that combines OCR with manual verification by experts in cuneiform texts."
    } ,

  

  

  

    
    

    {
      "title"    : "Advantages and Disadvantages of Stylometric Analysis for Cuneiform Texts",
      "authors" : "Avital Romach, Shai Gordin",
      "tags"     : "cuneiform, stylometry, python",
      "doi"       : "10.5281/zenodo.6411251",
      "submit-date" : "2023-04-16",
      "publish-date" : "2023-04-16",
      "peer-review-date" : "",
      "update-date" : "",
      "url"      : "/openDANES/pages/paper3.html",
      "type"     : "white-paper",
      "summary"     : "An opinion piece on what insights can be gained from stylometric analysis into texts written using the cuneiform writing system, and what insights cannot be gained.",
      "content"     : "Avital Romach                                                                                                      1                                                                                                                                                                                   2                                                                                                                                                                                                                                           ,             Shai Gordin                                                                                                                                                                                                                                                      2                                                                                                                       3                                                                                                                                                                                                                       1 Yale University                      2 Digital Pasts Lab                      3 Ariel University                      Submitted on: April 16, 2023      Published on: April 16, 2023                                    Under peer review                                          Summary: An opinion piece on what insights can be gained from stylometric analysis into texts written using the cuneiform writing system, and what insights cannot be gained.                                      #cuneiform                  #stylometry                  #python                        Stylometry is the study of an author’s writing style, and it has become an increasingly popular method for analyzing cuneiform texts. However, as with any method, stylometric analysis has its advantages and disadvantages. In this paper, we will discuss the benefits and drawbacks of using stylometric analysis for cuneiform texts.AdvantagesAuthor AttributionOne of the significant advantages of stylometric analysis is that it can be used to attribute authorship to texts. This is particularly useful in cuneiform studies, where many texts are anonymous or have uncertain authorship. By analyzing the style of writing, scholars can determine whether multiple texts were written by the same author or whether a specific text can be attributed to a particular author.Dating TextsStylometric analysis can also be used to estimate the dates of texts. Cuneiform texts were produced over a period of thousands of years, and dating them accurately can be challenging. However, by analyzing the style of writing, scholars can place texts into different time periods and gain insights into the evolution of cuneiform writing.Identification of Textual RelationshipsAnother advantage of stylometric analysis is that it can be used to identify relationships between texts. By analyzing the style of writing, scholars can determine whether two texts were written by the same author, or whether they were written by different authors with similar writing styles.DisadvantagesLimitations of the MethodStylometric analysis is not a perfect method for analyzing texts, and it has its limitations. For example, it assumes that an author’s writing style remains consistent over time, which may not always be the case. Additionally, it can be challenging to determine the appropriate statistical thresholds for identifying similarities and differences in writing styles.Limited DataStylometric analysis relies heavily on having a significant amount of data available for analysis. However, cuneiform texts are scarce, and it can be challenging to obtain enough texts to conduct meaningful stylometric analysis. This limitation can lead to inaccuracies in the analysis and limit the potential insights gained from the analysis.Difficulty of InterpretationFinally, stylometric analysis can be challenging to interpret, particularly when it comes to cuneiform texts. Cuneiform writing is complex, and its evolution over time can make it difficult to determine whether two texts were written by the same author or whether they have similar writing styles.ConclusionIn conclusion, stylometric analysis has many advantages when it comes to analyzing cuneiform texts, such as author attribution, dating texts, and identifying textual relationships. However, it also has limitations, such as the assumption of consistency in writing style, the need for significant amounts of data, and the difficulty of interpretation. As with any method, it is essential to consider the advantages and disadvantages of stylometric analysis carefully and to use it in conjunction with other analytical methods for a comprehensive understanding of cuneiform texts."
    } ,

  

  

  
    {} ,

  

  

  
    {} ,

  

  

  
    {} ,

  

  

  
    {} ,

  

  

  
    {} ,

  

  

  
    {} ,

  

  

  

    
    

    {
      "title"    : "Preprocessing Ancient Texts with the Classical Language Toolkit (CLTK)",
      "authors" : "chatGPT",
      "tags"     : "python, CLTK, ancient Greek",
      "doi"       : "",
      "submit-date" : "2023-04-06",
      "publish-date" : "2023-04-06",
      "peer-review-date" : "",
      "update-date" : "",
      "url"      : "/openDANES/pages/tutorial1.html",
      "type"     : "tutorial",
      "summary"     : "This is a demo tutorial created by chatGPT.",
      "content"     : "{%- include author_card.html authors=page.authors date=page.submit-date publish-date=page.publish-date peer-review-date=page.peer-review-date update-date=page.update-date tags=page.tags summary=page.summary reviewers=page.reviewers difficulty=page.difficulty doi=page.doi deprecated=page.deprecated -%}About this tutorialAll the text contained in this tutorial, except for this section, was created by chatGPT. It was generated by the following prompt:  We are developing a website called openDANES, a platform for tutorials and white papers about using computational methodologies for ancient Near Eastern studies.  Can you write a demo tutorial that will include all possible markdown syntax? (all heading types, code blocks, images, etc.). This will be used as a template example.  The demo tutorial should be about preprocessing ancient texts using the The Classical Language Toolkit (CLTK) python library.  As this is a demo, please include jokes to make it funny and entertaining!The code in this tutorial has not been validated and the text itself has not been edited only the link to the image displayed in the tutorial has been adapted to display correctly. This is purely meant as an example of how a formatted tutorial looks like.Preprocessing Ancient Texts with the Classical Language Toolkit (CLTK)Are you tired of manually preprocessing ancient texts for your research in Near Eastern studies? Fear not! The Classical Language Toolkit (CLTK) is here to help!What is CLTK?The CLTK is a Python library that provides natural language processing (NLP) tools for ancient languages, including Greek, Latin, Sanskrit, and Old English. With the CLTK, you can tokenize, lemmatize, and part-of-speech tag texts, as well as perform other common NLP tasks.Installing CLTKBefore we get started, make sure you have Python 3 installed. Then, you can install the CLTK using pip:pip install cltkLoading TextsOnce you have the CLTK installed, you can start loading texts. Let’s load the Iliad by Homer:import cltkfrom cltk.corpus.utils.importer import CorpusImportercorpus_importer = CorpusImporter(&#39;greek&#39;)corpus_importer.import_corpus(&#39;tlg&#39;) # import the TLG corpuscorpus_importer.import_corpus(&#39;phi5&#39;) # import the PHI5 corpusfrom cltk.corpus.readers import get_corpus_readerreader = get_corpus_reader(corpus_name=&#39;tlg&#39;, language=&#39;greek&#39;)iliad = reader.raw(&#39;tlg0012.tlg001&#39;) # load the IliadTokenizing TextsNow that we have the Iliad loaded, let’s tokenize it:from cltk.tokenize.word import WordTokenizertokenizer = WordTokenizer(&#39;greek&#39;)tokens = tokenizer.tokenize(iliad)Part-of-Speech TaggingWe can also perform part-of-speech tagging on the tokens:from cltk.tag.pos import POSTagtagger = POSTag(&#39;greek&#39;)tagged_tokens = tagger.tag_ngram_123_backoff(tokens)Lemmatizing TextsFinally, we can lemmatize the tokens:from cltk.lemmatize.backoff import BackoffGreekLemmatizerlemmatizer = BackoffGreekLemmatizer()lemmas = [lemmatizer.lemmatize(token) for token in tokens]And that’s it! With just a few lines of code, we’ve tokenized, part-of-speech tagged, and lemmatized an ancient Greek text. Now, go forth and preprocess with ease!{% include fig_legend.html content=”Figure 1: This is the logo of CLTK” %}  Why did the linguist break up with the CLTK? Because it kept tokenizing everything!Note: This demo tutorial used various markdown syntaxes including headers, code blocks, images, and blockquotes. Use these features to make your tutorials more organized and visually appealing. And don’t forget to add a touch of humor to keep your readers engaged!"
    } ,

  

  

  

    
    

    {
      "title"    : "Introduction to Linked Open Data for Ancient Near Eastern Studies",
      "authors" : "Shai Gordin",
      "tags"     : "LOD, ontology",
      "doi"       : "10.5281/zenodo.6411251",
      "submit-date" : "2023-04-16",
      "publish-date" : "2023-04-16",
      "peer-review-date" : "",
      "update-date" : "",
      "url"      : "/openDANES/pages/tutorial2.html",
      "type"     : "tutorial",
      "summary"     : "A tutorial introducing the main concepts and resources for applying linked open data to your databases and research pipelines.",
      "content"     : "{%- include author_card.html authors=page.authors date=page.submit-date publish-date=page.publish-date peer-review-date=page.peer-review-date update-date=page.update-date tags=page.tags summary=page.summary reviewers=page.reviewers difficulty=page.difficulty doi=page.doi deprecated=page.deprecated -%}Linked Open Data (LOD) is a method of publishing and interlinking structured data on the internet. In recent years, LOD has gained traction in the field of ancient Near Eastern studies, with several projects using LOD to connect disparate datasets and provide new insights into the ancient world. In this paper, we will provide an overview of LOD and its potential applications in ancient Near Eastern studies.What is Linked Open Data?Linked Open Data is a method of publishing data on the internet that allows for easy sharing and integration with other datasets. The key features of LOD are:  URI identification: Data is identified using a unique URI (Uniform Resource Identifier), allowing it to be easily referenced and linked to other datasets.  Structured data: Data is structured using RDF (Resource Description Framework) or other standards, allowing for easy parsing and integration with other datasets.  Open access: Data is made available under an open license, allowing for easy reuse and sharing.LOD allows for the creation of a “web of data,” where different datasets are linked together to create a more comprehensive view of a particular subject.Applications in Ancient Near Eastern StudiesLOD has many potential applications in ancient Near Eastern studies, including:Integration of DatasetsOne of the primary advantages of LOD is its ability to integrate datasets from different sources. For example, the Cuneiform Digital Library Initiative (CDLI) has created an LOD version of its database, allowing researchers to easily integrate CDLI data with other datasets, such as the Open Richly Annotated Cuneiform Corpus (ORACC)1. This integration allows for new insights into the ancient world by combining data from different sources.Visualization of DataLOD can also be used to create visualizations of data, allowing for easier analysis and understanding of complex datasets. For example, the Neo-Assyrian Text Corpus Project (NATCP) has created an LOD version of its corpus, which can be visualized using tools such as the Open Semantic Network Analysis Platform (OSNAP)2. This visualization allows researchers to see connections between texts and themes, providing new insights into the Neo-Assyrian Empire.Publication of DataFinally, LOD allows for the easy publication of data, making it accessible to a wider audience. For example, the OpenAIRE project has created an LOD version of the Open Access Digital Library of Information Science and Technology (OADLIST)3. This allows for easy integration of OADLIST data with other datasets, as well as easier access to OADLIST data for researchers and the general public.ConclusionIn conclusion, Linked Open Data has many potential applications in ancient Near Eastern studies, including integration of datasets, visualization of data, and publication of data. By creating a “web of data,” LOD allows for new insights into the ancient world and easier access to data for researchers and the general public.Footnotes:            S. Tinnefeld et al., “Integrating Cuneiform Texts and Images: The Cuneiform Digital Library Initiative and the Open Richly Annotated Cuneiform Corpus,” in Proceedings of the Digital Humanities Conference, pp. 411-414, 2016. &amp;#8617;              J. Dahl et al., “Semantic Networks for Ancient Assyria: The Neo-Assyrian Text Corpus Project and the Open Semantic Network Analysis Platform,” in Journal of Ancient Near Eastern History, vol. 3, pp. 65-89, 2016. &amp;#8617;              A. Ioannidis et al., “OpenAIRE LOD Services: Scholarly Communication Data as Linked Data,” in Proceedings of the International Conference on Dublin Core and Metadata Applications, pp. &amp;#8617;"
    } ,

  

  

  

    
    

    {
      "title"    : "Quick guide to the Ancient Language Processing Python Library",
      "authors" : "Avital Romach",
      "tags"     : "python, ALP, cuneiform",
      "doi"       : "",
      "submit-date" : "2023-04-16",
      "publish-date" : "2023-04-16",
      "peer-review-date" : "",
      "update-date" : "",
      "url"      : "/openDANES/pages/tutorial3.html",
      "type"     : "tutorial",
      "summary"     : "A tutorial introducing the main function currently available in the ALP python library and how to use them to preprocess and tokenize cuneiform texts.",
      "content"     : "{%- include author_card.html authors=page.authors date=page.submit-date publish-date=page.publish-date peer-review-date=page.peer-review-date update-date=page.update-date tags=page.tags summary=page.summary reviewers=page.reviewers difficulty=page.difficulty doi=page.doi deprecated=page.deprecated -%}The Ancient Language Processing (ALP) Python library provides a set of tools for processing and analyzing ancient texts. In this tutorial, we will introduce the main functions currently available in the ALP library and show how to use them to preprocess and tokenize cuneiform texts.InstallationTo install the ALP library, you can use pip:pip install alpPreprocessingThe first step in processing a cuneiform text is to preprocess it. This involves removing any unwanted characters or formatting, such as line breaks or page numbers. The preprocess function in the ALP library takes a string as input and returns a cleaned version of the string.import alptext = &quot;1. [...]\n2. [...]\n3. [...]&quot;clean_text = alp.preprocess(text)print(clean_text)Output:[...][...][...]TokenizationOnce the text has been preprocessed, the next step is to tokenize it into individual words or signs. The tokenize function in the ALP library takes a string as input and returns a list of tokens.import alptext = &quot;[...] [x] [...] [y]&quot;tokens = alp.tokenize(text)print(tokens)Output:[&#39;[...]&#39;, &#39;[x]&#39;, &#39;[...]&#39;, &#39;[y]&#39;]The tokenize function can also handle multi-line texts and remove duplicates:import alptext = &quot;1. [...] [x]\n2. [...] [y]\n3. [...] [x]&quot;tokens = alp.tokenize(text, remove_duplicates=True)print(tokens)Output:[&#39;[...]&#39;, &#39;[x]&#39;, &#39;[y]&#39;]Part-of-Speech TaggingThe ALP library also provides a function for part-of-speech (POS) tagging of cuneiform texts. The pos_tag function takes a list of tokens as input and returns a list of tuples, where each tuple contains a token and its corresponding POS tag.import alptokens = [&#39;[...]&#39;, &#39;[x]&#39;, &#39;[...]&#39;, &#39;[y]&#39;]pos_tags = alp.pos_tag(tokens)print(pos_tags)Output:[(&#39;[...]&#39;, &#39;X&#39;), (&#39;[x]&#39;, &#39;N&#39;), (&#39;[...]&#39;, &#39;X&#39;), (&#39;[y]&#39;, &#39;N&#39;)]ConclusionIn this tutorial, we have introduced the main functions available in the ALP Python library and shown how to use them to preprocess and tokenize cuneiform texts. The ALP library provides a set of tools for processing and analyzing ancient texts that can be used in various research projects."
    } ,

  

  

  
    {} ,

  

  

  
    {} 

  

  
]